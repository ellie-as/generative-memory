{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff56dd7-9567-49b8-9986-dadac44dd933",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boundary extension and contraction\n",
    "\n",
    "This notebook contains code for exploring boundary extension and contraction in a VAE trained on the shapes3d dataset.\n",
    "\n",
    "Tested with tensorflow 2.11.0 and Python 3.10.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc03a33-8116-4a38-8b01-6782a84a7654",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b5b4a-55de-4177-93ab-9d0b85c9886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec08c9-c699-4bdc-8bcb-91ba4b9a5399",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d654d64-ae02-44f6-ad6f-35d61dff4375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model, Sequential, metrics, optimizers, layers\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from utils import load_tfds_dataset\n",
    "from generative_model import encoder_network_large, decoder_network_large, VAE\n",
    "tf.keras.utils.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18735e9f-8c7d-4bbf-9943-689fc064eb68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds, train_labels, test_labels = load_tfds_dataset('shapes3d', labels=True, \n",
    "                                                                 key_dict= {'shapes3d': 'label_scale'})\n",
    "train_ds = train_ds / 255\n",
    "test_ds = test_ds / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ced13",
   "metadata": {},
   "source": [
    "#### Filter to just objects of mean size\n",
    "\n",
    "We can't use the object_size attribute directly because this is not equivalent to a 'close-up' or 'far away' view - the background is still the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = [img for img, label in zip(test_ds, test_labels) if label in [4,5]]\n",
    "test_ds = np.array(test_ds)\n",
    "test_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f4ee3-3430-4a85-b730-64f3ddb19c08",
   "metadata": {},
   "source": [
    "#### Load the trained VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298c6e7-25bc-4c0b-8275-17cb4a21bf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "latent_dim = 20\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "encoder, z_mean, z_log_var = encoder_network_large(input_shape, latent_dim)\n",
    "decoder = decoder_network_large(latent_dim)\n",
    "\n",
    "encoder.load_weights(\"model_weights/shapes3d_encoder.h5\")\n",
    "decoder.load_weights(\"model_weights/shapes3d_decoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3d67c-ca91-4fbd-a7bf-c5742363ca63",
   "metadata": {},
   "source": [
    "#### Test boundary extension / contraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13691a-829c-4491-aa65-f8ce1c1e1024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise(im_as_array):\n",
    "    img = Image.fromarray((im_as_array*255).astype(np.uint8))\n",
    "    gaussian = np.random.normal(0, 30, (img.size[0],img.size[1], 3))\n",
    "    noisy_img = img + gaussian\n",
    "    return np.clip(np.array(noisy_img), 0, 255) / 255\n",
    "\n",
    "def display_recalled(x_test_new, decoded_imgs, n=10):\n",
    "    plt.figure(figsize=(n*2, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test_new[i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + n + 1)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "code = Model(encoder.input, encoder.get_layer('mean').output)\n",
    "\n",
    "x_test_new = np.array([add_noise(image) for image in train_ds[0:20]])\n",
    "encoded_imgs = code.predict(x_test_new)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "display_recalled(x_test_new, decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08911a7-f5a1-4510-9cbd-87d183b5e5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_border(im_as_array, border_width=5):\n",
    "    img = Image.fromarray((im_as_array*255).astype(np.uint8))\n",
    "    im_crop = ImageOps.crop(img, border=border_width)\n",
    "    new_im = im_crop.resize((64,64))\n",
    "    return np.array(new_im) / 255\n",
    "\n",
    "x_test_new = np.array([remove_border(image) for image in train_ds[0:20]])\n",
    "encoded_imgs = code.predict(x_test_new)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "display_recalled(x_test_new, decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09e44f-6f78-487e-aa13-bcf883edf45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_border(img, border_width=5):\n",
    "    img = np.pad(img*255, pad_width=((border_width,border_width),\n",
    "                                     (border_width,border_width),\n",
    "                                     (0,0)), mode='edge')\n",
    "    img = Image.fromarray(img.astype(np.uint8))\n",
    "    img = img.resize((64,64))\n",
    "    return np.array(img)/255\n",
    "\n",
    "x_test_new = np.array([add_border(image) for image in train_ds[0:20]])\n",
    "encoded_imgs = code.predict(x_test_new)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "display_recalled(x_test_new, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4876bad",
   "metadata": {},
   "source": [
    "#### Plot boundary extension / contraction effects and prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15ca0f-2725-4f65-9769-1ce1135ee9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "border_const = 5\n",
    "\n",
    "def plot_zoom_rows(ind):\n",
    "    x_test_new_remove = np.array([add_noise(remove_border(train_ds[ind], border_width=border_const*i)) for i in range(5)])\n",
    "    x_test_new_no_noise_remove = np.array([remove_border(train_ds[ind], border_width=border_const*i) for i in range(5)])\n",
    "    encoded_imgs = code.predict(x_test_new_remove)\n",
    "    decoded_imgs_remove_border = decoder.predict(encoded_imgs)\n",
    "\n",
    "    recons_remove = tf.reduce_sum(keras.losses.mean_absolute_error(x_test_new_no_noise_remove, decoded_imgs_remove_border), axis=(1,2)).numpy().tolist()\n",
    "\n",
    "    x_test_new_add = np.array([add_noise(add_border(train_ds[ind], border_width=border_const*i)) for i in range(5)])\n",
    "    x_test_new_no_noise_add = np.array([add_border(train_ds[ind], border_width=border_const*i) for i in range(5)])\n",
    "    encoded_imgs = code.predict(x_test_new_add)\n",
    "    decoded_imgs_add_border = decoder.predict(encoded_imgs)\n",
    "\n",
    "    display_recalled(x_test_new_add[::-1].tolist() + x_test_new_remove.tolist()[1:], \n",
    "                     decoded_imgs_add_border[::-1].tolist() + decoded_imgs_remove_border.tolist()[1:], n=9)\n",
    "\n",
    "    recons_add = tf.reduce_sum(keras.losses.mean_absolute_error(x_test_new_no_noise_add, decoded_imgs_add_border), axis=(1,2)).numpy().tolist()\n",
    "    plt.figure(figsize=(18, 2))\n",
    "    plt.bar([str(border_const*i) for i in range(5)][::-1] + [str(-border_const*i) for i in range(5)][1:], recons_add[::-1] + recons_remove[1:])\n",
    "    plt.xlabel('Margin change (in pixels)', size=12)\n",
    "    plt.ylabel('Prediction error', size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f553b-b25b-44de-8382-1b526eefa250",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range (0,20):\n",
    "    plot_zoom_rows(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2a8a6",
   "metadata": {},
   "source": [
    "#### Plots for paper\n",
    "\n",
    "We want to plot a 'zoomed out' and a 'zoomed in' view, where the zoomed out view halves the central object size, and the zoomed in view doubles the central object size\n",
    "\n",
    "We have: ratio = shape_width_after / shape_width_before = width / (width + 2 * margin)\n",
    "This means margin = (32 / ratio) - 32\n",
    "So the margin for a ratio of 0.8 is 8, and for a ratio of 1.2 is - 5.33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_const = 5\n",
    "\n",
    "def plot_zoom_rows(ind):\n",
    "    x_test_new_remove = np.array([add_noise(remove_border(train_ds[ind], border_width=5.33*i)) for i in range(2)])\n",
    "    encoded_imgs = code.predict(x_test_new_remove)\n",
    "    decoded_imgs_remove_border = decoder.predict(encoded_imgs)\n",
    "\n",
    "    x_test_new_add = np.array([add_noise(add_border(train_ds[ind], border_width=8*i)) for i in range(2)])\n",
    "    encoded_imgs = code.predict(x_test_new_add)\n",
    "    decoded_imgs_add_border = decoder.predict(encoded_imgs)\n",
    "\n",
    "    display_recalled(x_test_new_add[::-1].tolist() + x_test_new_remove.tolist()[1:], \n",
    "                     decoded_imgs_add_border[::-1].tolist() + decoded_imgs_remove_border.tolist()[1:], n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5347c9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "    plot_zoom_rows(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
